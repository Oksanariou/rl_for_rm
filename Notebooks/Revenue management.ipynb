{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": "## Revenue Management\n### Dynamic Programming\n#### Model of the demand\n$D(t, p)\u003d D_ne^{-\\alpha(t)(\\frac{p}{p_n}-1)}$ \n  With:\n- $p_1 \u003e ... \u003e p_n$ the prices  \n- $\\alpha(t)$ the price sensitivity  \n- $D(t, p)$ the number of tickets sold  \n\n#### State\n$s \u003d (t, x)$  \n  With:\n- $t$ : time to departure  \n- $x$ : remaining capacity\n \nHypothesis: The time to departure is decomposed in micro-times $t$ in a non-linear way, meaning that $t$ can represent several weeks if we are far from departure and a few minutes if we are close to departure. Only one person can arrive per time interval $t$.\n#### Bellman optimality equation\n$v_*(t, x) \u003d P(\\mbox{person arrives})P(\\mbox{person buys})(\\mbox{price} + v_*(t-1, x-1)) + P(\\mbox{person arrives})P(\\mbox{person does not buy})v_*(t-1, x) + P(\\mbox{no one arrives})v_*(t-1, x)$\n $$v_*(t, x) \u003d \\max_{p\\in\\{p_1, ..., p_n\\}}\\{\\lambda(t)e^{-\\alpha(t)(\\frac{p}{p_n}-1)}(p + v_*(t-1, x-1))+ (1-\\lambda(t)e^{-\\alpha(t)(\\frac{p}{p_n}-1)})v_*(t-1,x)\\}$$  \n    With:\n- $\\lambda(t)$ the probability that a person arrives at $t$  \n- $e^{-\\alpha(t)(\\frac{p}{p_n}-1)}$ the purchase probability, the probability that the person buys a ticket  \n- $v_*(t, x)$ the optimal total revenue that the airline can earn if there are $t$ micro-times left and $x$ seats left  \n\n\nWe want to determine $p^* \u003d \\pi_*(x, t)$ the optimal price to which sell a seat if there are $t$ micro-times left and $x$ seats left. \nThe traditional RM approach uses historical booking database to estimate the forecast parameters ($\\lambda$, $\\alpha$). The Bellman equation is solved recursively to get $v_*(x,t)$. \n\n#### Initialization\nTerminal states:\n- $(0, x) \\forall x$, no more time left\n- $(t, 0) \\forall t$, no more seats left\n\nSo:\n- $v_*(0, x) \u003d 0 \\forall x$\n- $v_*(t, 0) \u003d 0 \\forall t$\n\n#### Probability of arriving $\\lambda(t)$\n$\\lambda(t)$ can be constant $\\forall t$.  \n Indeed if we fix $\\lambda(t) \u003d 0.2 \\forall t$ and the number of micro-times to $500$ that means that at the end of all the micro-times $100$ people on average arrived.\n %What does it mean to arrive ? Is it just to look at the prices of the flight ? Independent from the purchase probability ?\n \n #### Price sensitivity $\\alpha(t)$\n - $p_{50}(t)$ : price at which we sell a number of seats equal to half of the total capacity of the plane \n - FRat5 \u003d Fare Ratio at $50\\% \u003d \\frac{p_{50}(t)}{p_n} \u003d \\Phi(t) \u003e 1$  \n \n$\\alpha(t) \u003d \\frac{\\ln(2)}{\\frac{p_{50}(t)}{p_n}}\u003e0$  \nTo determine $\\alpha(t)$ we thus need to determine $\\Phi(t)$. $\\Phi(t)$ can be approximated by a logistic function that looks like $\\frac{L}{1+e^{-k(t-t_0)}}+b$. The parameters depend on the route, on the market.  \n$\\Phi(t)$ increases with time so $\\alpha$ decreases with time. For our first very naive approach we can suppose that $\\alpha(t)$ is constant.  \n\n#### Bid Prices\nIntuitively the Bid Price is the revenue that we would lose by giving away a seat for free. It is the optimal total revenue that the airline can earn at $(x,t)$ minus the optimal total revenue that the airline can earn with one seat less to sell.  \n$BP(t, x) \u003d v_*(t-1,x) - v_*(t-1, x-1)$  \nSo as far as the traditional approach in RM forecasting is concerned, once the historical booking database has been used to estimate the forecast parameters ($\\lambda, \\alpha$) the Bellman equation is solved recursively to obtain $V_*(x, t)$ which in turn allows us to get the bid price $BP(x,t)$.  \nFinally, the RM acceptance criterion in state $s\u003d(x, t)$ is: accept $f$ if $f\\geq BP(x,t)+FM$ where $FM \u003d \\frac{p_n}{\\alpha}$\n### Deep Q-Learning\n#### Network\nHere a neural network with an input dimension of $2$ and an output dimension of $n$ (the number of different price classes used).\nFor each state $(x, \\tau)$ the network produces $n$ Q-values, one for each class of price. The class of price with the highest Q-value is then picked up for the state $(x, \\tau)$.  \n#### Data Collection Points\nWith this DQL approach we no longer use micro-times $t$ but Data Collection Points (DCP) $\\tau$ which represent a grouping of micro-times. It is thus possible to have more than one buyer in a DCP.  \n#### Bellman equation\nThe Bellman equations for $Q$ become:  \n- if $\\tau_{i+1}-1 \\leq t \u003c \\tau_i -1 $ : \n$Q_*^{DQL}(t, x, p) \u003d \\lambda(t)e^{-\\alpha(t)(\\frac{p}{p_n}-1)}(p + Q_*^{DQL}(t-1, x-1, p)) + (1-\\lambda(t))e^{-\\alpha(t)(\\frac{p}{p_n}-1)}Q_*^{DQL}(t-1,x, p)$ \n- if $t \u003d \\tau_i - 1$:\n$Q_*^{DQL}(t, x, p) \u003d \\lambda(t)e^{-\\alpha(t)(\\frac{p}{p_n}-1)}(p + V_*^{RMS}(t-1, x-1)) + (1-\\lambda(t))e^{-\\alpha(t)(\\frac{p}{p_n}-1)}V_*^{RMS}(t-1, x-1)$  \nWith $V_*^{RMS}(t, x) \u003d \\max_pQ(t-1, x-1, p)$ \n\nThese equations are written for micro-times and they mean that at each DCP we can change the action and select the best one while we can not change the action if we are between two DCPs.\n\n#### Initialization\n- $Q(0, x, p) \u003d 0 \\forall x \\forall p$\n- $Q(t, C, p) \u003d 0 \\forall x \\forall p$\n- $Q(\\tau,x,p;\\theta_0) \u003d RMS$\n\n#### Training\n$L_{MB}(\\theta) \u003d \\sum_{(x, \\tau), p, (x\u0027, \\tau+1)\\in MB}(r + \\max_pQ(\\tau + 1, x\u0027, p; \\theta) - Q(\\tau, x, p;\\theta^-))^2$\n$\\theta_i \u003d \\underset{\\theta}{\\operatorname{argmin}}L_{MB}(\\theta)$"
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}